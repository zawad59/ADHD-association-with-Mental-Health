{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult Women Are the New Face of ADHD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29kaf8</td>\n",
       "      <td>http://www.thedailybeast.com/articles/2014/06/...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.404224e+09</td>\n",
       "      <td>2014-07-01 14:07:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why Women Hide Their ADHD Symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2ip2ra</td>\n",
       "      <td>https://euromd.com/9-diseases-and-conditions/1...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.412801e+09</td>\n",
       "      <td>2014-10-08 20:48:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult ADHD and Burnout: Success or Failure?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2q6jdk</td>\n",
       "      <td>http://rethinkadhd.wordpress.com/2014/12/23/ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.419349e+09</td>\n",
       "      <td>2014-12-23 15:34:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Am I And My ADHD Still Alive?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2sc7fa</td>\n",
       "      <td>http://blogs.psychcentral.com/adhd-man/2015/01...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.421192e+09</td>\n",
       "      <td>2015-01-13 23:35:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'd like to see this subreddit grow!</td>\n",
       "      <td>Hello, I'm a working, married, mother of 3.  I...</td>\n",
       "      <td>1</td>\n",
       "      <td>3296xx</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/32...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.428778e+09</td>\n",
       "      <td>2015-04-11 18:43:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0         Adult Women Are the New Face of ADHD   \n",
       "1           Why Women Hide Their ADHD Symptoms   \n",
       "2  Adult ADHD and Burnout: Success or Failure?   \n",
       "3            How Am I And My ADHD Still Alive?   \n",
       "4         I'd like to see this subreddit grow!   \n",
       "\n",
       "                                            selftext  score      id  \\\n",
       "0                                                NaN      3  29kaf8   \n",
       "1                                                NaN      3  2ip2ra   \n",
       "2                                                NaN      1  2q6jdk   \n",
       "3                                                NaN      2  2sc7fa   \n",
       "4  Hello, I'm a working, married, mother of 3.  I...      1  3296xx   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0  http://www.thedailybeast.com/articles/2014/06/...             0   \n",
       "1  https://euromd.com/9-diseases-and-conditions/1...             0   \n",
       "2  http://rethinkadhd.wordpress.com/2014/12/23/ad...             0   \n",
       "3  http://blogs.psychcentral.com/adhd-man/2015/01...             0   \n",
       "4  https://www.reddit.com/r/adhdwomen/comments/32...             1   \n",
       "\n",
       "    created_utc     created_datetime  \n",
       "0  1.404224e+09  2014-07-01 14:07:46  \n",
       "1  1.412801e+09  2014-10-08 20:48:14  \n",
       "2  1.419349e+09  2014-12-23 15:34:03  \n",
       "3  1.421192e+09  2015-01-13 23:35:23  \n",
       "4  1.428778e+09  2015-04-11 18:43:49  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "newDf = pd.read_csv('adhdwomen.csv')\n",
    "\n",
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>ADD Checklist</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>jts866</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/jt...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.605314e+09</td>\n",
       "      <td>2020-11-14 00:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>Taking Ritalin but still can't focus.</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>k6roh5</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/k6...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.607110e+09</td>\n",
       "      <td>2020-12-04 19:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Free Women’s Zoom ADHD Support Group!</td>\n",
       "      <td>Hello! I am an ADHD coach and offer a free wom...</td>\n",
       "      <td>21</td>\n",
       "      <td>hpyixe</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/hp...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.594576e+09</td>\n",
       "      <td>2020-07-12 17:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>Anybody else ever feel like this at the end of...</td>\n",
       "      <td>Picture this, you get home from work and now y...</td>\n",
       "      <td>58</td>\n",
       "      <td>jo6yps</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/jo...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.604531e+09</td>\n",
       "      <td>2020-11-04 22:56:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43723</th>\n",
       "      <td>This Sub Opened My Eyes</td>\n",
       "      <td>First - if you post here regularly or have rec...</td>\n",
       "      <td>41</td>\n",
       "      <td>mz936p</td>\n",
       "      <td>https://www.reddit.com/r/adhdwomen/comments/mz...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.619474e+09</td>\n",
       "      <td>2021-04-26 21:53:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "33003                                      ADD Checklist   \n",
       "12172              Taking Ritalin but still can't focus.   \n",
       "5192               Free Women’s Zoom ADHD Support Group!   \n",
       "32511  Anybody else ever feel like this at the end of...   \n",
       "43723                            This Sub Opened My Eyes   \n",
       "\n",
       "                                                selftext  score      id  \\\n",
       "33003                                          [deleted]      1  jts866   \n",
       "12172                                          [removed]      1  k6roh5   \n",
       "5192   Hello! I am an ADHD coach and offer a free wom...     21  hpyixe   \n",
       "32511  Picture this, you get home from work and now y...     58  jo6yps   \n",
       "43723  First - if you post here regularly or have rec...     41  mz936p   \n",
       "\n",
       "                                                     url  num_comments  \\\n",
       "33003  https://www.reddit.com/r/adhdwomen/comments/jt...             0   \n",
       "12172  https://www.reddit.com/r/adhdwomen/comments/k6...             1   \n",
       "5192   https://www.reddit.com/r/adhdwomen/comments/hp...             5   \n",
       "32511  https://www.reddit.com/r/adhdwomen/comments/jo...            20   \n",
       "43723  https://www.reddit.com/r/adhdwomen/comments/mz...            19   \n",
       "\n",
       "        created_utc     created_datetime  \n",
       "33003  1.605314e+09  2020-11-14 00:34:33  \n",
       "12172  1.607110e+09  2020-12-04 19:28:18  \n",
       "5192   1.594576e+09  2020-07-12 17:46:00  \n",
       "32511  1.604531e+09  2020-11-04 22:56:50  \n",
       "43723  1.619474e+09  2021-04-26 21:53:47  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDf = newDf.sample(frac=0.02, replace=True, random_state=1)\n",
    "\n",
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33003</th>\n",
       "      <td>ADD Checklist</td>\n",
       "      <td>1</td>\n",
       "      <td>jts866</td>\n",
       "      <td>2020-11-14 00:34:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>Taking Ritalin but still can't focus.</td>\n",
       "      <td>1</td>\n",
       "      <td>k6roh5</td>\n",
       "      <td>2020-12-04 19:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>Free Women’s Zoom ADHD Support Group!</td>\n",
       "      <td>21</td>\n",
       "      <td>hpyixe</td>\n",
       "      <td>2020-07-12 17:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>Anybody else ever feel like this at the end of...</td>\n",
       "      <td>58</td>\n",
       "      <td>jo6yps</td>\n",
       "      <td>2020-11-04 22:56:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43723</th>\n",
       "      <td>This Sub Opened My Eyes</td>\n",
       "      <td>41</td>\n",
       "      <td>mz936p</td>\n",
       "      <td>2021-04-26 21:53:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10247</th>\n",
       "      <td>University accommodations from disability serv...</td>\n",
       "      <td>1</td>\n",
       "      <td>jmwq5j</td>\n",
       "      <td>2020-11-02 21:32:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25518</th>\n",
       "      <td>Does anyone else feel like they have better qu...</td>\n",
       "      <td>26</td>\n",
       "      <td>g1784i</td>\n",
       "      <td>2020-04-14 15:08:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18891</th>\n",
       "      <td>Shut off button?</td>\n",
       "      <td>6</td>\n",
       "      <td>m3w58g</td>\n",
       "      <td>2021-03-13 01:27:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11090</th>\n",
       "      <td>ADHD or high prenatal levels of flouride?</td>\n",
       "      <td>0</td>\n",
       "      <td>jw83bk</td>\n",
       "      <td>2020-11-18 03:17:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24876</th>\n",
       "      <td>Finally seeing a GP about this.</td>\n",
       "      <td>1</td>\n",
       "      <td>f7q873</td>\n",
       "      <td>2020-02-22 09:08:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  score      id  \\\n",
       "33003                                      ADD Checklist      1  jts866   \n",
       "12172              Taking Ritalin but still can't focus.      1  k6roh5   \n",
       "5192               Free Women’s Zoom ADHD Support Group!     21  hpyixe   \n",
       "32511  Anybody else ever feel like this at the end of...     58  jo6yps   \n",
       "43723                            This Sub Opened My Eyes     41  mz936p   \n",
       "...                                                  ...    ...     ...   \n",
       "10247  University accommodations from disability serv...      1  jmwq5j   \n",
       "25518  Does anyone else feel like they have better qu...     26  g1784i   \n",
       "18891                                   Shut off button?      6  m3w58g   \n",
       "11090          ADHD or high prenatal levels of flouride?      0  jw83bk   \n",
       "24876                    Finally seeing a GP about this.      1  f7q873   \n",
       "\n",
       "          created_datetime  \n",
       "33003  2020-11-14 00:34:33  \n",
       "12172  2020-12-04 19:28:18  \n",
       "5192   2020-07-12 17:46:00  \n",
       "32511  2020-11-04 22:56:50  \n",
       "43723  2021-04-26 21:53:47  \n",
       "...                    ...  \n",
       "10247  2020-11-02 21:32:14  \n",
       "25518  2020-04-14 15:08:40  \n",
       "18891  2021-03-13 01:27:39  \n",
       "11090  2020-11-18 03:17:33  \n",
       "24876  2020-02-22 09:08:38  \n",
       "\n",
       "[888 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDf = newDf.drop(['selftext','url','num_comments','created_utc'],axis='columns')\n",
    "newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 888 entries, 33003 to 24876\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   title             888 non-null    object\n",
      " 1   score             888 non-null    int64 \n",
      " 2   id                888 non-null    object\n",
      " 3   created_datetime  888 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 34.7+ KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newDf.info(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                                        ADD Checklist\n",
       "12172                Taking Ritalin but still can't focus.\n",
       "5192                 Free Women’s Zoom ADHD Support Group!\n",
       "32511    Anybody else ever feel like this at the end of...\n",
       "43723                              This Sub Opened My Eyes\n",
       "                               ...                        \n",
       "10247    University accommodations from disability serv...\n",
       "25518    Does anyone else feel like they have better qu...\n",
       "18891                                     Shut off button?\n",
       "11090            ADHD or high prenatal levels of flouride?\n",
       "24876                      Finally seeing a GP about this.\n",
       "Name: title, Length: 888, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "STOPWORDS = stopwords.words('english')\n",
    "PUNCTUATION = string.punctuation\n",
    "\n",
    "def remove_urls(text):    \n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "newDf['title'] = newDf['title'].apply(remove_urls)\n",
    "\n",
    "newDf['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                                        add checklist\n",
       "12172                taking ritalin but still can't focus.\n",
       "5192                 free women’s zoom adhd support group!\n",
       "32511    anybody else ever feel like this at the end of...\n",
       "43723                              this sub opened my eyes\n",
       "                               ...                        \n",
       "10247    university accommodations from disability serv...\n",
       "25518    does anyone else feel like they have better qu...\n",
       "18891                                     shut off button?\n",
       "11090            adhd or high prenatal levels of flouride?\n",
       "24876                      finally seeing a gp about this.\n",
       "Name: title, Length: 888, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDf['title'] = newDf['title'].str.lower()\n",
    "newDf['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                                        add checklist\n",
       "12172                  taking ritalin but still cant focus\n",
       "5192                  free women’s zoom adhd support group\n",
       "32511    anybody else ever feel like this at the end of...\n",
       "43723                              this sub opened my eyes\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punctuation = \"\".join([word for word in text if word not in PUNCTUATION])\n",
    "    return no_punctuation\n",
    "\n",
    "newDf['title'] = newDf['title'].apply(remove_punctuation)\n",
    "\n",
    "newDf['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                                        add checklist\n",
       "12172                  taking ritalin but still cant focus\n",
       "5192                  free women’s zoom adhd support group\n",
       "32511    anybody else ever feel like this at the end of...\n",
       "43723                              this sub opened my eyes\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_extra_white_spaces(text):\n",
    "    single_char_pattern = r'\\s+[a-zA-Z]\\s+'\n",
    "    without_sc = re.sub(pattern=single_char_pattern, repl=\" \", string = text)\n",
    "    return without_sc\n",
    "\n",
    "newDf['title'] = newDf['title'].apply(remove_extra_white_spaces)\n",
    "\n",
    "newDf['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                               add checklist\n",
       "12172             taking ritalin still cant focus\n",
       "5192         free women ’ zoom adhd support group\n",
       "32511    anybody else ever feel like end long day\n",
       "43723                             sub opened eyes\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    no_stopwords = []    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in STOPWORDS:\n",
    "            no_stopwords.append(tokens[i])\n",
    "            \n",
    "    return \" \".join(no_stopwords)\n",
    "\n",
    "newDf['title'] = newDf['title'].apply(remove_stopwords)\n",
    "newDf['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def drop_duplicates(row):\n",
    "    # Split string by ', ', drop duplicates and join back.\n",
    "    words = row.split(', ')\n",
    "    return ', '.join(np.unique(words).tolist())\n",
    "newDf['title'] = newDf['title'].apply(drop_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33003                               add checklist\n",
       "12172             taking ritalin still cant focus\n",
       "5192         free woman ’ zoom adhd support group\n",
       "32511    anybody else ever feel like end long day\n",
       "43723                              sub opened eye\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatize_text(text):    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    for i in range(len(tokens)):\n",
    "        lemma_word = lemmatizer.lemmatize(tokens[i])\n",
    "        tokens[i] = lemma_word\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "newDf['title'] = newDf['title'].apply(lemmatize_text)\n",
    "newDf['title'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "list1 = []\n",
    "def generate_N_grams(text,ngram=1):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    tokens = [token for token in text.split(\" \") if token != \"\"]\n",
    "    output = list(ngrams(tokens, ngram))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('anyone', 'else', 'struggle'), ('think', 'might', 'adhd'), ('anyone', 'else', 'feel'), ('else', 'feel', 'like'), ('anyone', 'else', 'get'), ('experience', 'know', 'adhd'), ('know', 'adhd', 'med'), ('adhd', 'med', 'birth'), ('med', 'birth', 'control'), ('anyone', 'else', 'wrap'), ('else', 'wrap', 'present'), ('wrap', 'present', 'christmas'), ('present', 'christmas', 'eve'), ('christmas', 'eve', 'night'), ('saw', 'social', 'dilemma'), ('social', 'dilemma', 'yesterday'), ('dilemma', 'yesterday', 'really'), ('yesterday', 'really', 'triggered'), ('really', 'triggered', 'imposter'), ('triggered', 'imposter', 'feeling'), ('wfi', 'booster', 'gate'), ('booster', 'gate', 'tell'), ('gate', 'tell', 'ive'), ('tell', 'ive', 'read'), ('ive', 'read', 'short'), ('read', 'short', 'material'), ('short', 'material', 'distracted'), ('material', 'distracted', 'detail'), ('living', 'extremely', 'tidy'), ('extremely', 'tidy', 'people')]\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for X in newDf['title']:\n",
    "    y = generate_N_grams(X,3)\n",
    "    lst.append(y)\n",
    "\n",
    "def flatten(input):\n",
    "    new_list = []\n",
    "    for i in input:\n",
    "        for j in i:\n",
    "            new_list.append(j)\n",
    "    return new_list\n",
    "\n",
    "lst1 = flatten(lst)\n",
    "\n",
    "finalList1 = []\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter(lst1)\n",
    "M = c.most_common(30)\n",
    "\n",
    "for key,val in M:\n",
    "    finalList1.append(key)\n",
    "\n",
    "print(finalList1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  1942\n",
      "Word: ID\n",
      "adhd:  2\n",
      "anybody:  158\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(newDf['title'])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Total number of words: \", total_words)\n",
    "print(\"Word: ID\")\n",
    "print(\"adhd: \", tokenizer.word_index['adhd'])\n",
    "print(\"anybody: \", tokenizer.word_index['anybody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences:  3999\n",
      "[88, 61]\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for line in newDf['title']:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    #print(token_list)\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# print(input_sequences)\n",
    "print(\"Total input sequences: \", len(input_sequences))\n",
    "print(input_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0, 88, 61])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0 88]\n"
     ]
    }
   ],
   "source": [
    "xs = input_sequences[:,:-1]\n",
    "print(xs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "labels = input_sequences[:,-1]\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "3999/3999 [==============================] - 11s 3ms/sample - loss: 7.5079 - acc: 0.0240\n",
      "Epoch 2/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 6.7427 - acc: 0.0413\n",
      "Epoch 3/20\n",
      "3999/3999 [==============================] - 10s 2ms/sample - loss: 5.9676 - acc: 0.0618\n",
      "Epoch 4/20\n",
      "3999/3999 [==============================] - 10s 2ms/sample - loss: 4.6403 - acc: 0.1398\n",
      "Epoch 5/20\n",
      "3999/3999 [==============================] - 11s 3ms/sample - loss: 3.2007 - acc: 0.3273\n",
      "Epoch 6/20\n",
      "3999/3999 [==============================] - 11s 3ms/sample - loss: 1.8161 - acc: 0.5934\n",
      "Epoch 7/20\n",
      "3999/3999 [==============================] - 10s 3ms/sample - loss: 1.0191 - acc: 0.7704\n",
      "Epoch 8/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.6806 - acc: 0.8510\n",
      "Epoch 9/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.5389 - acc: 0.8775\n",
      "Epoch 10/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.4715 - acc: 0.8842\n",
      "Epoch 11/20\n",
      "3999/3999 [==============================] - 10s 2ms/sample - loss: 0.4532 - acc: 0.8817\n",
      "Epoch 12/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.4381 - acc: 0.8830\n",
      "Epoch 13/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.4171 - acc: 0.8840\n",
      "Epoch 14/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.4078 - acc: 0.8845\n",
      "Epoch 15/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.4005 - acc: 0.8840\n",
      "Epoch 16/20\n",
      "3999/3999 [==============================] - 10s 2ms/sample - loss: 0.3913 - acc: 0.8845\n",
      "Epoch 17/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.3888 - acc: 0.8840\n",
      "Epoch 18/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.3805 - acc: 0.8870\n",
      "Epoch 19/20\n",
      "3999/3999 [==============================] - 9s 2ms/sample - loss: 0.3842 - acc: 0.8830\n",
      "Epoch 20/20\n",
      "3999/3999 [==============================] - 10s 2ms/sample - loss: 0.3775 - acc: 0.8860\n",
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x00000117B67ADDA0>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=20, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyone else experience overwhelm avalanche feel defeated general like suicidey would share something helpful im overwhelmed trying organize prioritize figure daily task night\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"anyone else experience\"\n",
    "next_words = 20\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feel like im really productive day better failure planner planner love swear erin condren seems month start missing deadline relatable read sentence immediately\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"feel like im\"\n",
    "next_words = 20\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medication question x adderall xr adderall xr surrounding adhd thanks say say care deep hurt thought night able able relate lol\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"medication\"\n",
    "next_words = 20\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
